\doxysection{Class List}
Here are the classes, structs, unions and interfaces with brief descriptions\+:\begin{DoxyCompactList}
\item\contentsline{section}{\mbox{\hyperlink{structstd_1_1hash_3_01Parameter_3_01T_01_4_01_4}{std\+::hash$<$ Parameter$<$ T $>$ $>$}} \\*Implementation of the hash function for a Parameter of type T (necessary for having an unordered set of Parameters) }{\pageref{structstd_1_1hash_3_01Parameter_3_01T_01_4_01_4}}{}
\item\contentsline{section}{\mbox{\hyperlink{classinput_1_1Instance}{input\+::\+Instance$<$ T $>$}} \\*An instance, i.\+e. a data point from the instance set. Always a vector whose elements are of type T }{\pageref{classinput_1_1Instance}}{}
\item\contentsline{section}{\mbox{\hyperlink{classknearest_1_1KNearestNeighbors}{knearest\+::\+K\+Nearest\+Neighbors$<$ T, Q $>$}} \\*K-\/\+Nearest Neighbors algorithm implementation }{\pageref{classknearest_1_1KNearestNeighbors}}{}
\item\contentsline{section}{\mbox{\hyperlink{classinput_1_1LabeledInstance}{input\+::\+Labeled\+Instance$<$ T, Q $>$}} \\*An instance tagged with a label. An element used to construct a sample }{\pageref{classinput_1_1LabeledInstance}}{}
\item\contentsline{section}{\mbox{\hyperlink{classlearner_1_1Learner}{learner\+::\+Learner$<$ T, Q, P $>$}} \\*Abstract learner interface, inherited by all classification/regression-\/based algorithms }{\pageref{classlearner_1_1Learner}}{}
\item\contentsline{section}{\mbox{\hyperlink{classloss_1_1LossFunction}{loss\+::\+Loss\+Function$<$ T, Q $>$}} \\*Abstract interface representing a loss function }{\pageref{classloss_1_1LossFunction}}{}
\item\contentsline{section}{\mbox{\hyperlink{classparameter_1_1Parameter}{parameter\+::\+Parameter$<$ T $>$}} \\*A (hyper)parameter, i.\+e. a parameter that is passed to a learner and that influences its training and prediction phases }{\pageref{classparameter_1_1Parameter}}{}
\item\contentsline{section}{\mbox{\hyperlink{classparameter_1_1ParameterSet}{parameter\+::\+Parameter\+Set$<$ T $>$}} \\*A fixed set of parameters, to be used for iterating on a subset of a certain parameter space }{\pageref{classparameter_1_1ParameterSet}}{}
\item\contentsline{section}{\mbox{\hyperlink{classparameter_1_1ParameterSpace}{parameter\+::\+Parameter\+Space$<$ T $>$}} \\*A generic parameter space, set where a certain parameter lives (i.\+e. can take values) }{\pageref{classparameter_1_1ParameterSpace}}{}
\item\contentsline{section}{\mbox{\hyperlink{classsample_1_1Sample}{sample\+::\+Sample$<$ T, Q $>$}} \\*A sample, i.\+e. a sequence of labeled data points }{\pageref{classsample_1_1Sample}}{}
\item\contentsline{section}{\mbox{\hyperlink{classsample_1_1SlicedSample}{sample\+::\+Sliced\+Sample$<$ T, Q, k $>$}} \\*A sample that has been `sliced' into k disjoint subsets }{\pageref{classsample_1_1SlicedSample}}{}
\item\contentsline{section}{\mbox{\hyperlink{classsample_1_1SlicedSettedSample}{sample\+::\+Sliced\+Setted\+Sample$<$ T, Q, k $>$}} \\*A \mbox{\hyperlink{classsample_1_1SlicedSample}{Sliced\+Sample}} with a `set' subset. This is used for Cross-\/\+Validation }{\pageref{classsample_1_1SlicedSettedSample}}{}
\item\contentsline{section}{\mbox{\hyperlink{classloss_1_1SquaredLoss}{loss\+::\+Squared\+Loss$<$ T, Q $>$}} \\*The squared loss, a concrete implementation of the abstract Loss function interface }{\pageref{classloss_1_1SquaredLoss}}{}
\item\contentsline{section}{\mbox{\hyperlink{structsample_1_1ValidationSample}{sample\+::\+Validation\+Sample$<$ T, Q $>$}} \\*Object aggregating a training set and a test set }{\pageref{structsample_1_1ValidationSample}}{}
\item\contentsline{section}{\mbox{\hyperlink{classloss_1_1ZeroOneLoss}{loss\+::\+Zero\+One\+Loss$<$ T, Q $>$}} \\*The 0-\/1 loss, a concrete implementation of the abstract Loss function interface }{\pageref{classloss_1_1ZeroOneLoss}}{}
\end{DoxyCompactList}
